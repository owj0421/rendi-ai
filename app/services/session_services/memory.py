from datetime import datetime
from typing import Dict, Optional, List, Literal

from pydantic import BaseModel, Field

from ..elements import Message
from ...utils.prompt_utils import load_prompt
from ...core import clients, logger

log = logger.get_logger(__name__)

# === Constants ===

N_MESSAGES = 15
PARTNER_MEMORY_CATEGORIES = [
    "ì·¨ë¯¸/ê´€ì‹¬ì‚¬",
    "ê³ ë¯¼",
    "ê°€ì¡±/ì¹œêµ¬",
    "ì§ì—…/í•™ì—…",
    "ì„±ê²©/ê°€ì¹˜ê´€",
    "ì´ìƒí˜•/ì—°ì• ê´€",
    "ìƒí™œìŠµê´€",
]

# === Models ===

class PartnerMemoryRelevance(BaseModel):
    """
    íŒŒíŠ¸ë„ˆ ë©”ì‹œì§€ê°€ ë©”ëª¨ë¦¬ì— ê¸°ì–µë  í•„ìš”ê°€ ìˆëŠ”ì§€ ì—¬ë¶€ë¥¼ ë‚˜íƒ€ë‚´ëŠ” ëª¨ë¸.
    """
    should_remember: bool


class PartnerMemoryUpdateInstruction(BaseModel):
    """
    íŒŒíŠ¸ë„ˆ ë©”ì„¸ì§€ê°€ ë©”ëª¨ë¦¬ì— ì—…ë°ì´íŠ¸ë  í•„ìš”ê°€ ìˆëŠ”ì§€ ì—¬ë¶€ì™€
    ì—…ë°ì´íŠ¸í•  ì¹´í…Œê³ ë¦¬ ë° ë‚´ìš©ì„ í¬í•¨í•˜ëŠ” ëª¨ë¸.
    """
    should_update: bool
    category: Optional[Literal[
        'ì·¨ë¯¸/ê´€ì‹¬ì‚¬',
        'ê³ ë¯¼',
        'ê°€ì¡±/ì¹œêµ¬',
        'ì§ì—…/í•™ì—…',
        'ì„±ê²©/ê°€ì¹˜ê´€',
        'ì´ìƒí˜•/ì—°ì• ê´€',
        'ìƒí™œìŠµê´€',
    ]]
    content: Optional[str] = None
    

class PartnerMemory(BaseModel):
    content: Dict[str, List[str]]
    

# === ConversationMemory ===

class ConversationMemory:
    """
    ëŒ€í™” ë©”ëª¨ë¦¬ë¥¼ ê´€ë¦¬í•˜ëŠ” í´ë˜ìŠ¤.
    """
    def __init__(
        self,
        my_info: Optional[Dict] = None,
        partner_info: Optional[Dict] = None,
    ):
        self.my_info = my_info or {}
        self.partner_info = partner_info or {}
        self.start_time = datetime.now()
        self.messages: List[Message] = []
        self.partner_memory: PartnerMemory = PartnerMemory(
            content={
                category: [] for category in PARTNER_MEMORY_CATEGORIES
            }
        )

    def add_message(self, message: Message) -> None:
        # ì¤‘ë³µ ë©”ì‹œì§€ í•„í„°ë§ì€ ì™¸ë¶€ì—ì„œ ì²˜ë¦¬í•œë‹¤ê³  ê°€ì •
        self.messages.append(message)

    def get_recent_messages(self, n: Optional[int] = None) -> List[Message]:
        return self.messages[-n:] if n else self.messages

    def is_message_exists(self, message: Message) -> bool:
        return self.messages and self.messages[-1].message_id >= message.message_id

    def update_partner_memory(
        self,
        instruction: PartnerMemoryUpdateInstruction,
    ) -> None:
        if instruction.should_update and instruction.category and instruction.content:
            self.partner_memory.content[instruction.category].append(instruction.content)

    def get_elapsed_time_str(self) -> str:
        elapsed = datetime.now() - self.start_time
        hours, remainder = divmod(int(elapsed.total_seconds()), 3600)
        minutes, seconds = divmod(remainder, 60)
        return f"{hours}ì‹œê°„ {minutes}ë¶„ {seconds}ì´ˆ"

    def prompt_conversation_info(self) -> str:
        return (
            "### ğŸ“ ëŒ€í™” ì •ë³´:\n"
            f"â° ëŒ€í™” ê²½ê³¼ ì‹œê°„: {self.get_elapsed_time_str()}\n"
            f"ğŸ’¬ ì´ ë©”ì‹œì§€ ìˆ˜: {len(self.messages)}íšŒ\n"
        )

    def prompt_messages(self, n_messages: Optional[int] = None) -> str:
        prompt = "### ğŸ’¬ ëŒ€í™” ë‚´ìš©:\n"
        messages_to_show = self.get_recent_messages(n_messages)
        if n_messages and len(self.messages) > n_messages:
            prompt += "...ì´ì „ ë©”ì‹œì§€ ì¼ë¶€ ìƒëµ...\n"
        for msg in messages_to_show:
            prompt += msg.to_prompt()
        return prompt

    def prompt_partner_memory(self) -> str:
        prompt = "### ğŸ“ íŒŒíŠ¸ë„ˆì— ëŒ€í•œ ë©”ëª¨:\n"
        for category, memos in self.partner_memory.content.items():
            if not memos:
                continue
            prompt += f"<{category}>ì™€ ê´€ë ¨ëœ ë©”ëª¨:\n"
            for idx, memo in enumerate(memos):
                prompt += f"- {idx}: {memo}\n"
        return prompt
        

class PartnerMemoryRelevanceClassifier:
    PROMPT_NAME = "memory/partner_message_relevance_classifier"
    PROMPT_VER = 1
    LLM_MODEL = "gpt-4.1-nano"

    @classmethod
    def _generate_prompt(cls, conversation_memory: ConversationMemory) -> List[Dict[str, str]]:
        system_message = {
            "role": "system",
            "content": load_prompt(cls.PROMPT_NAME, "system", cls.PROMPT_VER).format(
                categories=", ".join(PARTNER_MEMORY_CATEGORIES)
            )
        }
        user_message = {
            "role": "user",
            "content": '\n---\n'.join([
                conversation_memory.prompt_messages(n_messages=N_MESSAGES),
                f"### ğŸ” ë¶„ì„í•  ë©”ì‹œì§€:\n{conversation_memory.messages[-1].to_prompt()}"
            ])
        }
        return [system_message, user_message]
    
    @classmethod
    async def do(cls, conversation_memory: ConversationMemory) -> PartnerMemoryRelevance:
        prompt_messages = cls._generate_prompt(conversation_memory)

        response = await clients.async_openai_client.beta.chat.completions.parse(
            messages=prompt_messages,
            model=cls.LLM_MODEL,
            response_format=PartnerMemoryRelevance,
        )
        response = response.choices[0].message.parsed

        return response


class PartnerMemoryUpdateInstructionGenerator:
    PROMPT_NAME = "memory/partner_memory_update_instruction_generator"
    PROMPT_VER = 1
    LLM_MODEL = "gpt-4.1-mini"

    @classmethod
    def _generate_prompt(cls, conversation_memory: ConversationMemory) -> List[Dict[str, str]]:
        system_message = {
            "role": "system",
            "content": load_prompt(cls.PROMPT_NAME, "system", cls.PROMPT_VER).format(
                categories=", ".join(PARTNER_MEMORY_CATEGORIES)
            )
        }
        user_message = {
            "role": "user",
            "content": '\n---\n'.join([
                conversation_memory.prompt_partner_memory(),
                conversation_memory.prompt_messages(n_messages=N_MESSAGES),
                f"### ğŸ” ë¶„ì„í•  ë©”ì‹œì§€:\n{conversation_memory.messages[-1].to_prompt()}"
            ])
        }

        return [system_message, user_message]
    
    @classmethod
    async def do(cls, conversation_memory: ConversationMemory) -> None:
        prompt_messages = cls._generate_prompt(conversation_memory)

        response = await clients.async_openai_client.beta.chat.completions.parse(
            messages=prompt_messages,
            model=cls.LLM_MODEL,
            response_format=PartnerMemoryUpdateInstruction,
        )
        response = response.choices[0].message.parsed
            
        return response

# === Functions ===
    
async def update_partner_memory_pipeline(
    conversation_memory: ConversationMemory,
) -> PartnerMemoryUpdateInstruction:
    
    if conversation_memory.messages[-1].role != "íŒŒíŠ¸ë„ˆ":
        instruction = PartnerMemoryUpdateInstruction(
            should_update=False,
            category=None,
            content=None
        )
    else:
        relevance = await PartnerMemoryRelevanceClassifier.do(
            conversation_memory=conversation_memory
        )
        
        if relevance.should_remember:
            instruction = await PartnerMemoryUpdateInstructionGenerator.do(
                conversation_memory=conversation_memory
            )
        else:
            instruction = PartnerMemoryUpdateInstruction(
                should_update=False,
                category=None,
                content=None
            )
    
    conversation_memory.update_partner_memory(
        instruction=instruction
    )
    